{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b481bba4baf043f8a2c441cdcc95cb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bde92bcf814cb78e49f145d8dcc26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_recall, context_precision, answer_correctness\n",
    "import pandas as pd\n",
    "from rag_pipeline import create_rag_pipeline, create_embeddings, create_vector_store\n",
    "\n",
    "# Load your documents (use the same documents as the Chainlit app)\n",
    "pdf_path_1 = \"../docs/Blueprint-for-an-AI-Bill-of-Rights.pdf\"\n",
    "pdf_path_2 = \"../docs/NIST_AI_600-1.pdf\"\n",
    "loader1 = PyMuPDFLoader(pdf_path_1)\n",
    "loader2 = PyMuPDFLoader(pdf_path_2)\n",
    "documents1 = loader1.load()\n",
    "documents2 = loader2.load()\n",
    "documents = documents1 + documents2\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter_eval = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "eval_documents = text_splitter_eval.split_documents(documents)\n",
    "\n",
    "# Set up embeddings using ADA\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "embeddings = create_embeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "# Set up the Qdrant vector store\n",
    "vectorstore = create_vector_store(eval_documents, embeddings)\n",
    "\n",
    "# Create the RAG pipeline using the current ADA model\n",
    "retriever = vectorstore.as_retriever()\n",
    "rag_pipeline = create_rag_pipeline(retriever)\n",
    "\n",
    "# Define the LLMs for test set generation\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Initialize the TestsetGenerator\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Define test set distribution (simple, multi_context, reasoning)\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "# Generate synthetic test set (5 QA pairs for this example)\n",
    "num_qa_pairs = 5\n",
    "testset = generator.generate_with_langchain_docs(eval_documents, num_qa_pairs, distributions)\n",
    "\n",
    "# Convert test set to pandas DataFrame for inspection\n",
    "testset_df = testset.to_pandas()\n",
    "testset_df.to_csv(\"testset.csv\")\n",
    "\n",
    "# Load the test set questions and ground truth answers\n",
    "test_df = pd.read_csv(\"testset.csv\")\n",
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the answers and context lists\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "# Generate answers using the current RAG pipeline\n",
    "for question in test_questions:\n",
    "    # Invoke the RAG pipeline and get the response\n",
    "    response = rag_pipeline.invoke({\"query\": question})\n",
    "    \n",
    "    # Append the generated answer (content) from the response\n",
    "    answers.append(response.content)\n",
    "    \n",
    "    # Access the retrieved context separately from the response if available\n",
    "    retrieved_context = response.additional_kwargs.get(\"context\", [])\n",
    "    contexts.append([context.page_content for context in retrieved_context])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0a4f1573b34acbb7bf06966a5cd3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question contexts  \\\n",
      "0  What information should be documented regardin...       []   \n",
      "1  What is the importance of implementing safety ...       []   \n",
      "2  How is the AI model validated and documented f...       []   \n",
      "3  How can diverse AI teams establish contextual ...       []   \n",
      "4  How do privacy risks increase with GAI using p...       []   \n",
      "\n",
      "                                              answer  \\\n",
      "0  The information that should be documented rega...   \n",
      "1  The importance of implementing safety measures...   \n",
      "2  The AI model is explained, validated, and docu...   \n",
      "3  To establish contextual relevance with domain ...   \n",
      "4  Privacy risks increase with GAI using personal...   \n",
      "\n",
      "                                        ground_truth  faithfulness  \\\n",
      "0  Information about the AI system's knowledge li...           0.0   \n",
      "1  Implementing safety measures, both prior to de...           0.0   \n",
      "2  The AI model is validated, explained, and docu...           0.0   \n",
      "3  Establishing contextual relevance with domain ...           0.0   \n",
      "4  GAI systems raise privacy risks when using per...           0.0   \n",
      "\n",
      "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
      "0          0.978509             0.0                0.0            0.819001  \n",
      "1          0.958209             0.0                0.0            0.702688  \n",
      "2          0.920134             0.0                0.0            0.479674  \n",
      "3          0.943181             0.0                0.0            0.318461  \n",
      "4          0.958900             0.0                0.0            0.993818  \n"
     ]
    }
   ],
   "source": [
    "# Create the HuggingFace Dataset for evaluation\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\": test_questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": test_groundtruths\n",
    "})\n",
    "\n",
    "# Evaluate using RAGAS metrics\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness\n",
    "]\n",
    "results = evaluate(response_dataset, metrics)\n",
    "\n",
    "# Convert results to pandas DataFrame for analysis\n",
    "results_df = results.to_pandas()\n",
    "print(results_df)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"ragas_evaluation_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
