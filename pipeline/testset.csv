,question,contexts,ground_truth,evolution_type,metadata,episode_done
0,What information should be documented regarding the AI system's knowledge limits and how its output may be utilized and overseen by humans?,"['decision-making criteria. \nIntellectual Property; Data Privacy \nAI Actor Tasks: TEVV \n \nMAP 2.2: Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is \ndocumented. Documentation provides suﬃcient information to assist relevant AI Actors when making decisions and taking \nsubsequent actions. \nAction ID \nSuggested Action \nGAI Risks \nMP-2.2-001 \nIdentify and document how the system relies on upstream data sources, \nincluding for content provenance, and if it serves as an upstream dependency for \nother systems.']","Information about the AI system's knowledge limits and how its output may be utilized and overseen by humans should be documented. This documentation should provide sufficient information to assist relevant AI Actors in making decisions and taking subsequent actions. Specifically, it should identify and document how the system relies on upstream data sources, including content provenance, and whether it serves as an upstream dependency for other systems.",simple,"[{'source': '../docs/NIST_AI_600-1.pdf', 'file_path': '../docs/NIST_AI_600-1.pdf', 'page': 27, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': ""D:20240805141702-04'00'"", 'modDate': ""D:20240805143048-04'00'"", 'trapped': ''}]",True
1,"What is the importance of implementing safety measures, both prior to deployment and on an ongoing basis, in the context of CBRN information or capabilities and information security?","['safety measures, both prior to deployment and on an ongoing basis, through \ninternal and external evaluations. \nCBRN Information or Capabilities; \nInformation Security \nAI Actor Tasks: Governance and Oversight \n \nGOVERN 1.3: Processes, procedures, and practices are in place to determine the needed level of risk management activities based \non the organization’s risk tolerance. \nAction ID \nSuggested Action \nGAI Risks \nGV-1.3-001 \nConsider the following factors when updating or deﬁning risk tiers for GAI: Abuses \nand impacts to information integrity; Dependencies between GAI and other IT or']","Implementing safety measures, both prior to deployment and on an ongoing basis, is crucial in the context of CBRN information or capabilities and information security to ensure the protection of critical assets and data. These measures help in mitigating risks, identifying vulnerabilities, and maintaining the integrity and confidentiality of sensitive information. Additionally, they contribute to the overall resilience and preparedness of the organization against potential threats and cyber attacks.",simple,"[{'source': '../docs/NIST_AI_600-1.pdf', 'file_path': '../docs/NIST_AI_600-1.pdf', 'page': 17, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': ""D:20240805141702-04'00'"", 'modDate': ""D:20240805143048-04'00'"", 'trapped': ''}]",True
2,"How is the AI model validated and documented for responsible use, governance, security, and vulnerabilities?","['35 \nMEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context – as \nidentiﬁed in the MAP function – to inform responsible use and governance. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.9-001 \nApply and document ML explanation results such as: Analysis of embeddings, \nCounterfactual prompts, Gradient-based attributions, Model \ncompression/surrogate models, Occlusion/term reduction. \nConfabulation \nMS-2.9-002 \nDocument GAI model details including: Proposed use and organizational value;', '33 \nMEASURE 2.7: AI system security and resilience – as identiﬁed in the MAP function – are evaluated and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.7-001 \nApply established security measures to: Assess likelihood and magnitude of \nvulnerabilities and threats such as backdoors, compromised dependencies, data \nbreaches, eavesdropping, man-in-the-middle attacks, reverse engineering, \nautonomous agents, model theft or exposure of model weights, AI inference, \nbypass, extraction, and other baseline security concerns. \nData Privacy; Information Integrity;']","The AI model is validated, explained, and documented to inform responsible use and governance. This includes applying and documenting ML explanation results such as analysis of embeddings, counterfactual prompts, gradient-based attributions, model compression/surrogate models, and occlusion/term reduction. Additionally, GAI model details are documented, including proposed use, organizational value, security measures, and evaluation of vulnerabilities and threats like backdoors, compromised dependencies, data breaches, and other security concerns.",multi_context,"[{'source': '../docs/NIST_AI_600-1.pdf', 'file_path': '../docs/NIST_AI_600-1.pdf', 'page': 38, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': ""D:20240805141702-04'00'"", 'modDate': ""D:20240805143048-04'00'"", 'trapped': ''}, {'source': '../docs/NIST_AI_600-1.pdf', 'file_path': '../docs/NIST_AI_600-1.pdf', 'page': 36, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': ""D:20240805141702-04'00'"", 'modDate': ""D:20240805143048-04'00'"", 'trapped': ''}]",True
3,How can diverse AI teams establish contextual relevance with domain expertise?,"['AI Actor Tasks: AI Deployment \n \nMAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context reﬂect demographic diversity and \nbroad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary \ncollaboration are prioritized. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.2-001 \nEstablish and empower interdisciplinary teams that reﬂect a wide range of \ncapabilities, competencies, demographic groups, domain expertise, educational']","Establishing contextual relevance with domain expertise can be achieved by empowering interdisciplinary teams that reflect a wide range of capabilities, competencies, demographic groups, and educational backgrounds. By prioritizing opportunities for interdisciplinary collaboration, AI actors can ensure that diverse perspectives and expertise are incorporated into the deployment process.",multi_context,"[{'source': '../docs/NIST_AI_600-1.pdf', 'file_path': '../docs/NIST_AI_600-1.pdf', 'page': 26, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': ""D:20240805141702-04'00'"", 'modDate': ""D:20240805143048-04'00'"", 'trapped': ''}]",True
4,"How do privacy risks increase with GAI using personal data for training, considering transparency, participation, and purpose?","['2.4. Data Privacy \nGAI systems raise several risks to privacy. GAI system training requires large volumes of data, which in \nsome cases may include personal data. The use of personal data for GAI training raises risks to widely \naccepted privacy principles, including to transparency, individual participation (including consent), and \npurpose speciﬁcation. For example, most model developers do not disclose speciﬁc data sources on \nwhich models were trained, limiting user awareness of whether personally identiﬁably information (PII) \nwas trained on and, if so, how it was collected.']","GAI systems raise privacy risks when using personal data for training due to potential violations of transparency, individual participation (including consent), and purpose specification. Model developers often do not disclose specific data sources used for training, limiting user awareness of potential exposure of personally identifiable information (PII) and how it was collected.",reasoning,"[{'source': '../docs/NIST_AI_600-1.pdf', 'file_path': '../docs/NIST_AI_600-1.pdf', 'page': 10, 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'author': 'National Institute of Standards and Technology', 'subject': '', 'keywords': '', 'creator': 'Acrobat PDFMaker 24 for Word', 'producer': 'Adobe PDF Library 24.2.159', 'creationDate': ""D:20240805141702-04'00'"", 'modDate': ""D:20240805143048-04'00'"", 'trapped': ''}]",True
