{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install sentence-transformers datasets huggingface_hub pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install sentence-transformers datasets huggingface_hub pandas scikit-learn accelerate transformers[torch] -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import notebook_login\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Ensure that PyTorch uses GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the fine-tuning dataset\n",
    "df = pd.read_csv(\"ai_regulation_finetuning_dataset.csv\")\n",
    "print(df.head())\n",
    "\n",
    "# Ensure the dataset has the necessary columns\n",
    "assert 'question' in df.columns, \"The dataset must have a 'question' column.\"\n",
    "assert 'content' in df.columns, \"The dataset must have a 'content' column.\"\n",
    "assert 'score' in df.columns, \"The dataset must have a 'score' column representing similarity scores.\"\n",
    "\n",
    "# Convert 'score' to float\n",
    "df['score'] = df['score'].astype(float)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets (80/10/10 split)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Prepare the dataset for SentenceTransformers\n",
    "# Each InputExample includes texts and a label (similarity score)\n",
    "train_samples = [InputExample(texts=[row['question'], row['content']], label=row['score']) for _, row in train_df.iterrows()]\n",
    "val_samples = [InputExample(texts=[row['question'], row['content']], label=row['score']) for _, row in val_df.iterrows()]\n",
    "test_samples = [InputExample(texts=[row['question'], row['content']], label=row['score']) for _, row in test_df.iterrows()]\n",
    "\n",
    "# Load the pre-trained Snowflake model using SentenceTransformers\n",
    "model_id = \"Snowflake/snowflake-arctic-embed-m\"\n",
    "model = SentenceTransformer(model_id, device=device)\n",
    "\n",
    "# Create DataLoaders for training\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)\n",
    "\n",
    "# Define the loss function (Cosine Similarity Loss)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Define an evaluator for validation\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_samples, name='val')\n",
    "\n",
    "# Calculate warm-up steps\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)  # 10% of training steps\n",
    "\n",
    "# Fine-tune the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_steps=100,  # Adjust based on dataset size\n",
    "    output_path=\"./snowflake-arctic-embed-m-finetuned\",\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model locally\n",
    "model.save(\"./snowflake-arctic-embed-m-finetuned\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='test')\n",
    "test_evaluator(model, output_path=\"./snowflake-arctic-embed-m-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to Hugging Face Hub\n",
    "# notebook_login()\n",
    "\n",
    "import getpass\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the token as an environment variable\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass('Enter your Hugging Face access token: ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da57e5718374890a96b5a5605ce6d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e989f202c83e4348985c71cd6f96bb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/gmedrano/snowflake-arctic-embed-m-finetuned/commit/ef5dd989eebc5abbdb48b04229cb4685c5e66e8f'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the fine-tuned model to the Hugging Face Hub\n",
    "model.push_to_hub(\"gmedrano/snowflake-arctic-embed-m-finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
